{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do_HESZgU06R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Bi-pDTjU06V"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3ElzNLTU06W",
        "outputId": "0925a596-7e1b-4721-d97f-9c9bb9b35294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 14, 14, 32)   320         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 7, 7, 64)     18496       ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 3136)         0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 16)           50192       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 2)            34          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 2)            34          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " sampling (Sampling)            (None, 2)            0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 69,076\n",
            "Trainable params: 69,076\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "latent_dim = 2\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = layers.Conv2D(32, 3, activation=\"tanh\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"tanh\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16, activation=\"tanh\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B__dOjkVU06Y",
        "outputId": "b251d434-678b-498f-c9b6-f09c4b3778a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3136)              9408      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       36928     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        289       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65,089\n",
            "Trainable params: 65,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(7 * 7 * 64, activation=\"tanh\")(latent_inputs)\n",
        "x = layers.Reshape((7, 7, 64))(x)\n",
        "x = layers.Conv2DTranspose(64, 3, activation=\"tanh\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"tanh\", strides=2, padding=\"same\")(x)\n",
        "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glkzM5YPU06Z"
      },
      "outputs": [],
      "source": [
        "\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZSRMxXiU06a",
        "outputId": "8b87437c-5ab5-4db2-c80a-aa6e25e1ce28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 13s 14ms/step - loss: 276.4325 - reconstruction_loss: 224.4695 - kl_loss: 4.2791\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 208.2777 - reconstruction_loss: 206.9095 - kl_loss: 0.8822\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 206.7999 - reconstruction_loss: 206.5899 - kl_loss: 0.1976\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 206.7312 - reconstruction_loss: 206.4288 - kl_loss: 0.0356\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 206.1906 - reconstruction_loss: 206.3481 - kl_loss: 0.0166\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.3427 - reconstruction_loss: 206.2944 - kl_loss: 0.0115\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.4244 - reconstruction_loss: 206.2971 - kl_loss: 0.0086\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 206.4765 - reconstruction_loss: 206.2620 - kl_loss: 0.0071\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.1164 - reconstruction_loss: 206.2637 - kl_loss: 0.0046\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 205.8168 - reconstruction_loss: 206.2284 - kl_loss: 0.0048\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.3615 - reconstruction_loss: 206.2143 - kl_loss: 0.0044\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.2475 - reconstruction_loss: 206.2165 - kl_loss: 0.0037\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.0972 - reconstruction_loss: 206.2349 - kl_loss: 0.0041\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.1709 - reconstruction_loss: 206.2159 - kl_loss: 0.0031\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 205.9986 - reconstruction_loss: 206.2042 - kl_loss: 0.0027\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.1287 - reconstruction_loss: 206.2002 - kl_loss: 0.0025\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.1148 - reconstruction_loss: 206.1808 - kl_loss: 0.0025\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 4s 16ms/step - loss: 206.2124 - reconstruction_loss: 206.1983 - kl_loss: 0.0024\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.1794 - reconstruction_loss: 206.1817 - kl_loss: 0.0022\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.0457 - reconstruction_loss: 206.1754 - kl_loss: 0.0023\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.0329 - reconstruction_loss: 206.1855 - kl_loss: 0.0022\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.0551 - reconstruction_loss: 206.1719 - kl_loss: 0.0018\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 4s 16ms/step - loss: 206.0119 - reconstruction_loss: 206.1898 - kl_loss: 0.0020\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 5s 18ms/step - loss: 206.3378 - reconstruction_loss: 206.1183 - kl_loss: 0.0017\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 5s 19ms/step - loss: 206.3344 - reconstruction_loss: 206.1625 - kl_loss: 0.0017\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 4s 15ms/step - loss: 206.2868 - reconstruction_loss: 206.1634 - kl_loss: 0.0015\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.1067 - reconstruction_loss: 206.1451 - kl_loss: 0.0015\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 205.9374 - reconstruction_loss: 206.1351 - kl_loss: 0.0016\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.2485 - reconstruction_loss: 206.1409 - kl_loss: 0.0018\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.3416 - reconstruction_loss: 206.1399 - kl_loss: 0.0014\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.1159 - reconstruction_loss: 206.1340 - kl_loss: 0.0013\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.0552 - reconstruction_loss: 206.1160 - kl_loss: 0.0014\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.1107 - reconstruction_loss: 206.1531 - kl_loss: 0.0015\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 4s 16ms/step - loss: 205.8308 - reconstruction_loss: 206.1188 - kl_loss: 0.0013\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 205.9492 - reconstruction_loss: 206.1347 - kl_loss: 0.0011\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.1557 - reconstruction_loss: 206.1122 - kl_loss: 0.0012\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.0146 - reconstruction_loss: 206.1282 - kl_loss: 0.0010\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.1985 - reconstruction_loss: 206.1286 - kl_loss: 0.0013\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 205.7919 - reconstruction_loss: 206.1070 - kl_loss: 0.0011\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 206.0513 - reconstruction_loss: 203.5131 - kl_loss: 0.3696\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 174.8634 - reconstruction_loss: 167.4023 - kl_loss: 4.4867\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 166.7253 - reconstruction_loss: 160.5675 - kl_loss: 4.9610\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 4s 16ms/step - loss: 162.6796 - reconstruction_loss: 156.9957 - kl_loss: 5.1738\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 160.2760 - reconstruction_loss: 154.9144 - kl_loss: 5.3041\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 159.1179 - reconstruction_loss: 153.4073 - kl_loss: 5.3943\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 157.9239 - reconstruction_loss: 152.2233 - kl_loss: 5.4677\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 156.7871 - reconstruction_loss: 151.2806 - kl_loss: 5.5433\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 156.0082 - reconstruction_loss: 150.4587 - kl_loss: 5.6058\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 155.8728 - reconstruction_loss: 149.6935 - kl_loss: 5.6615\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 154.6576 - reconstruction_loss: 149.0278 - kl_loss: 5.7157\n"
          ]
        }
      ],
      "source": [
        "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
        "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
        "\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "history = vae.fit(mnist_digits, epochs=50, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "plt.figure(figsize=(10, 8))\n",
        "hist_df.plot()\n",
        "# hist_df.plot(y='reconstruction_loss', label='decoder loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('Losses_Adam.png',dpi=300)\n",
        "files.download(\"Losses_Adam.png\") \n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "W9M7wXa0jbNS",
        "outputId": "57ef13bd-89ef-4e05-fe5f-c39e83f2eaf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8a9f9b5e-0c44-465a-8831-f28fc57c05aa\", \"Losses_Adam.png\", 66123)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hThhqUAjU06a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_latent_space(vae, n=30, figsize=15):\n",
        "    # display a n*n 2D manifold of digits\n",
        "    digit_size = 28\n",
        "    scale = 1.0\n",
        "    figure = np.zeros((digit_size * n, digit_size * n))\n",
        "    # linearly spaced coordinates corresponding to the 2D plot\n",
        "    # of digit classes in the latent space\n",
        "    grid_x = np.linspace(-scale, scale, n)\n",
        "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
        "\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            z_sample = np.array([[xi, yi]])\n",
        "            x_decoded = vae.decoder.predict(z_sample)\n",
        "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "            figure[\n",
        "                i * digit_size : (i + 1) * digit_size,\n",
        "                j * digit_size : (j + 1) * digit_size,\n",
        "            ] = digit\n",
        "\n",
        "    plt.figure(figsize=(figsize, figsize))\n",
        "    start_range = digit_size // 2\n",
        "    end_range = n * digit_size + start_range\n",
        "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
        "    sample_range_x = np.round(grid_x, 1)\n",
        "    sample_range_y = np.round(grid_y, 1)\n",
        "    plt.xticks(pixel_range, sample_range_x)\n",
        "    plt.yticks(pixel_range, sample_range_y)\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.imshow(figure, cmap=\"Greys_r\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_latent_space(vae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "407oSZhqU06b"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_label_clusters(vae, data, labels):\n",
        "    # display a 2D plot of the digit classes in the latent space\n",
        "    z_mean, _, _ = vae.encoder.predict(data)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
        "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
        "\n",
        "plot_label_clusters(vae, x_train, y_train)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}