{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do_HESZgU06R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Bi-pDTjU06V"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3ElzNLTU06W",
        "outputId": "0a5e098a-4659-4114-9e9e-116ea488a1fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 14, 14, 32)   320         ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 7, 7, 64)     18496       ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 3136)         0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 16)           50192       ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 2)            34          ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 2)            34          ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " sampling_2 (Sampling)          (None, 2)            0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 69,076\n",
            "Trainable params: 69,076\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "latent_dim = 2\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = layers.Conv2D(32, 3, activation=\"tanh\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"tanh\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16, activation=\"tanh\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B__dOjkVU06Y",
        "outputId": "bf158656-ef15-48e1-a584-99017e1d2a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3136)              9408      \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose_6 (Conv2DT  (None, 14, 14, 64)       36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_7 (Conv2DT  (None, 28, 28, 32)       18464     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_8 (Conv2DT  (None, 28, 28, 1)        289       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65,089\n",
            "Trainable params: 65,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(7 * 7 * 64, activation=\"tanh\")(latent_inputs)\n",
        "x = layers.Reshape((7, 7, 64))(x)\n",
        "x = layers.Conv2DTranspose(64, 3, activation=\"tanh\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"tanh\", strides=2, padding=\"same\")(x)\n",
        "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glkzM5YPU06Z"
      },
      "outputs": [],
      "source": [
        "\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZSRMxXiU06a",
        "outputId": "8fdf60e2-27e3-4da2-b73d-54fd4f2be0e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 88779.9348 - reconstruction_loss: 86111.5859 - kl_loss: 0.0064\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 82876.0757 - reconstruction_loss: 82571.1094 - kl_loss: 0.0030\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 81092.6796 - reconstruction_loss: 82423.6094 - kl_loss: 0.0023\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 84620.8103 - reconstruction_loss: 83338.6016 - kl_loss: 0.0019\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 81943.4347 - reconstruction_loss: 82863.4062 - kl_loss: 0.0016\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 83321.5210 - reconstruction_loss: 83042.6797 - kl_loss: 0.0014\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 82679.8346 - reconstruction_loss: 82893.2500 - kl_loss: 0.0013\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 82152.5221 - reconstruction_loss: 82434.4453 - kl_loss: 0.0012\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 85072.3130 - reconstruction_loss: 83362.2109 - kl_loss: 0.0011\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 81582.7348 - reconstruction_loss: 82597.7891 - kl_loss: 9.8821e-04\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 83198.3331 - reconstruction_loss: 83402.8594 - kl_loss: 9.1948e-04\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 82159.0945 - reconstruction_loss: 82551.7188 - kl_loss: 8.6024e-04\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 84537.6045 - reconstruction_loss: 83369.5000 - kl_loss: 8.0843e-04\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 81883.8464 - reconstruction_loss: 83018.1641 - kl_loss: 7.6305e-04\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 81397.5356 - reconstruction_loss: 82419.3125 - kl_loss: 7.2251e-04\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 83161.4083 - reconstruction_loss: 82548.5000 - kl_loss: 6.8620e-04\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 83785.9724 - reconstruction_loss: 83111.1172 - kl_loss: 6.5370e-04\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 82621.8546 - reconstruction_loss: 83029.5312 - kl_loss: 6.2426e-04\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 81960.3796 - reconstruction_loss: 82190.8125 - kl_loss: 5.9706e-04\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 84902.7047 - reconstruction_loss: 83645.0859 - kl_loss: 5.7270e-04\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 81862.2321 - reconstruction_loss: 82808.7188 - kl_loss: 5.4995e-04\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 83959.6181 - reconstruction_loss: 83214.4766 - kl_loss: 5.2927e-04\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 82027.9654 - reconstruction_loss: 82856.4062 - kl_loss: 5.0975e-04\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 80509.1205 - reconstruction_loss: 82498.5469 - kl_loss: 4.9185e-04\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 81839.7861 - reconstruction_loss: 82364.6875 - kl_loss: 4.7512e-04\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 84349.0914 - reconstruction_loss: 83497.3984 - kl_loss: 4.5947e-04\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 81840.7135 - reconstruction_loss: 82136.9766 - kl_loss: 4.4498e-04\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 84418.3874 - reconstruction_loss: 83016.4609 - kl_loss: 4.3122e-04\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 82987.1336 - reconstruction_loss: 82482.8281 - kl_loss: 4.1854e-04\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 81242.6803 - reconstruction_loss: 82643.3281 - kl_loss: 4.0640e-04\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 81845.2538 - reconstruction_loss: 82472.8359 - kl_loss: 3.9487e-04\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 84571.3909 - reconstruction_loss: 82683.3906 - kl_loss: 3.8415e-04\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 84235.5409 - reconstruction_loss: 83395.2891 - kl_loss: 3.7394e-04\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 81303.3594 - reconstruction_loss: 82454.1406 - kl_loss: 3.6417e-04\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 82568.2557 - reconstruction_loss: 82939.6875 - kl_loss: 3.5513e-04\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 82653.2966 - reconstruction_loss: 82691.0547 - kl_loss: 3.4630e-04\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 83029.2706 - reconstruction_loss: 83298.9844 - kl_loss: 3.3798e-04\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 82076.4694 - reconstruction_loss: 82686.8828 - kl_loss: 3.3005e-04\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 84408.6750 - reconstruction_loss: 83043.9844 - kl_loss: 3.2257e-04\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 81764.4589 - reconstruction_loss: 82339.8203 - kl_loss: 3.1535e-04\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 84686.1248 - reconstruction_loss: 83214.1016 - kl_loss: 3.0842e-04\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 81707.5755 - reconstruction_loss: 82363.8359 - kl_loss: 3.0184e-04\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 82558.1371 - reconstruction_loss: 82174.5859 - kl_loss: 2.9549e-04\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 82862.1874 - reconstruction_loss: 83287.3594 - kl_loss: 2.8932e-04\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 82305.7983 - reconstruction_loss: 82676.0547 - kl_loss: 2.8351e-04\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 83104.0314 - reconstruction_loss: 81978.0234 - kl_loss: 2.7794e-04\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 81145.5056 - reconstruction_loss: 82228.3281 - kl_loss: 2.7258e-04\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 82279.0266 - reconstruction_loss: 82506.8125 - kl_loss: 2.6738e-04\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 84080.6607 - reconstruction_loss: 82393.7500 - kl_loss: 2.6234e-04\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 85365.1683 - reconstruction_loss: 83743.7812 - kl_loss: 2.5756e-04\n"
          ]
        }
      ],
      "source": [
        "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
        "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
        "\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.SGD())\n",
        "history = vae.fit(mnist_digits, epochs=50, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "plt.figure(figsize=(10, 8))\n",
        "hist_df.plot()\n",
        "# hist_df.plot(y='reconstruction_loss', label='decoder loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('Losses_SGD.png',dpi=300)\n",
        "files.download(\"Losses_SGD.png\") \n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "W9M7wXa0jbNS",
        "outputId": "38674e7e-787a-46dc-9421-0770eb6170d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1ddc2720-843e-4f3f-8a06-d50b560deebf\", \"Losses_SGD.png\", 68125)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV9Z3/8dcnGwlZISD7KggimxoWtUjVFtAy4kK11ipQW39trdrfdKw67TxaHZ2x2p+OthZ//qqAjh13lHEpOi5FqgIBQfZVloQlC0nIQrabz++Pe0KDsoRDFiDv5+NxHzn3e5b7+cJN3vd7zrnnmLsjIiISRkxrFyAiIicvhYiIiISmEBERkdAUIiIiEppCREREQotr7QJaWqdOnbxv376tXYaIyElj6dKlBe7e+VDz2lyI9O3bl+zs7NYuQ0TkpGFm2w43T7uzREQkNIWIiIiEphAREZHQFCIiIhKaQkREREJTiIiISGgKERERCU0h0gh1kQifzv5nNi7/qLVLERE5oShEGqG0ZC99t75A8uvfp2RvfmuXIyJywlCINEJ6x84UT36STnWFfPGnG6iLRFq7JBGRE4JCpJEGZ13CssE/Z2TFJyx+7jetXY6IyAlBIXIMxlx7N8tSxpO1+Q+s+eTt1i5HRKTVKUSOgcXEMPCHs9kV05XT5v+Igt3bW7skEZGjqotE2PnFumbZtkLkGKWmd6R26mySvYI9T3+P2prqY1rf6+oo2LmNSG1tM1V4eJHaWnI2rWr0a9dFImz+/GNyt6xu9GvsLy9ly6pFlBTuwevqwpbaIlZ//BafP/ANlj30Dyx5/Y+UFO5p7ZKoqa5i2fxnyX7jSWqqq1q7nKMqLy1mXfZ77C8vbdbXOdbfs9Z2orz36yIRlr71FNvvH0nMnG9RVVnR5K9h7t7kGz2RZWVleVNcCn7Ja39g1PJf8kmP6Zz3w0ePuKzX1bF55cfkf/pf9Nn9Dt09j/2eQE58H4pSBlLX+UySe42g64ARRCK1VJQUsn9fIdVle6kp30tdRTHExBKTmEZ8+zTi22eQkJxBYko6Gaf1Ii0j84ivvX7ZBxQvfp7T896lM0WUkMymlFFETv8G/cdcTqfufQ4sX1FWwvqP/5uatW/Tr+hvdKYIgC9i+rC7+yV0yrqKAcMvwGL+/vmjYOc2tnz8Cglb3mFQ+VKSLPoLX+pJ5MV1Y19id6pSemEd+5Fx+ij6DTufhHaJx/xvvjcvlx2r/kbF1iXElubise2ij7h2EJeIxSYQ074DPbO+Rfe+gw67nS2rFlH65q8YsX8x+XQAoDNF1HoM69sNo7TvBHqf/206devDrq3r2LttFVV7NhCzdzMpZVtJipRRktiNypRe0KEviZ37k9FjIF16DyIpOfWY+1X/b7jxL49z+vaXOI29AOy0LuQOu4WRk39EfEK7w667a9t6cld8QEq3AfQZMiZ0DY1RU13F5s/+StHqd0nf9TEDqteSYBEqvB1r0scRN+LbDPnaFYf9/43U1pK7ZRU1VZWkd+5Bh07diI07+I4UtTXVbF2zhMJ1HxGbu4TupSvpWpfHttje5GWMIKb3GLoOHU/P/mcd9D7cX17Knu3rKd65iar8L0jo0J3+WZNIz+xy2P6Ulxaz7qO5sPZ1UvbvYm+3cZw26ir6Dx170LYbY9e29Wx9548MzH0NgB3JQ6nqlkXGGV+j77DzSUxKPqbtHY9IbS3L588mc+l/0LduB9tiepF/7u2cPXHGV/69G8PMlrp71iHnKUTCW/zo9YwueoNPB/yMxK6DiW+fTrvkdJJSM0hKyaBozw7yPv0veu2cT0/fRY3HsjbpHCp6jYOSXFJK1tOt6gsyKTmuOvLoyO7E/lSkDySm6xAy+gzHYmIpWPQifXb/he6eR7XHsTp5DNV9LiRm13L6FX9CJ4oB2Bzbj/xOY2hfsplB+5fTzmoo9SQ2pI6hbsA3iVQUk7r1LwyuWkWsObvpxLbOX6cuKZPMnR9wRu0GAHbaaezodCGxfcZQW7ILK9pGYvkOMqp20SWym0SrAaDK4/kifgDFmSNJ6DuG7kPHkdQ+lf3l+6gq30dleQk1+0up2V9K1Z4NJOz5jG5la+lG9PTqOjcKLYM4IiR4NQnUEG8HnzG3JaYve3p8g85ZV3L6sPOxmBh2bl1P7txfcW7xu5RZe9b0v4mRU+8koV0Sm1Z8RGH2q3Tb/T5963YAEHEj1v7++1FIOnnxPamKTyOtMtqnZKs86HULyKAgvjtlSd2pTetDTGY/krucTvv0TNolZ5CUnEb71HTaJbbH6+pYu/gd9v/tCYbvW0C8Rfg8MYu6rB8AkPzJ7xgY2USudSF3+K2cM/l/ERefAEDOplXs+PgFOm1/m4G1Gw+8fsSNHbG9yE89k0iX4aT1O5eY2DiqyoupqSgmUl5MXeU+qCyBmFgsMZ2YpAzikjNISO5Au9SOmMWwv6SAqtI8ImWF1JUXElNRSGLZdgbsX0myVVLnxua40yk47XwSeo2kdtOHDNr7PhmUUUwKGzpeRPtzrgEzyratICZvNR3KNtKrZuuB90F9vUWWzr6YDMoSMomtq6Ff1XraW3QUlk8HdiQPoyq9L8l719K3cjVpRD9NF5HGjsRBJETK6VSz88D7uaH6Ogs7j6H94EsYkPUNampq2LDgReLWv8GZ5YtJtBqKSCMvrhsDazYQY85OO43tnS8ideQVDB494bB/eOsiEVYueBVf8hTDyj/FgM/bj6EmIY1u+z6np+8GoNrj+CJ+AEWdziVp0EUMyPomyakZh/6FPoKa6ir25uVQkpeDmZGQlEJCUjKJ7dNISk4lPiHxK+FRcO7PGDlxeqjwqKcQaaApQ6SyoowdD3/9oF/iL4u4sSZxJPvPmMIZ468jo1PXryxTuCeHXRuWUr5zLRabQFxyBxJSOpKYlkn7tE4kp2fidREqSovZX1ZMVXkx1eXF1JYXU1OcS3zBWjLKt9CrdjvtGvyC1ngsa5LOoXrwFQz6+nUHjVi8ro4tqxeTt+y/Scv9K2dUrWF3TBdyTxtPyvBvMWjUhK98+i3K38XGhS8Rv/FtzixfQgK1bIw/g6Ke36DLqCn0PXPUYT+9eV0de3K3sHP1Qqq/+JSMvSvoV73xoHoPZ6d1YVfymdR0HUna6WPpM/S8r/wC1tZUU121n8JdW8ldNJe0be8yqHr1gdDbmTyEoWUf4xjLul/LkG//hvSOh7xRGzmbVpGz6BV8fzHxp51BWs8z6dL3rK8s73V1FBXsIn/7ekp3b6ImfzOxJdtJrsilY/VOTvOCg0KooWqPpZoEUmw/+0hmTZd/oMc3f0qvAcMO2v6K918g5ZOHGBDZTI51JafLJZyW9zf6120FYEPcGeztPYlOIyZRuucLKnd8RvuClXTfv+HAKPJQaj0Gww9b35eVkExRTCZ7OpxD/MCLOH3UpV/5hF9dVcnav71GzfKXGFLy0YEgANhLGrntTqc8YzCx3YYS2y6Zmn178NI8YiryiK8sJLm6AICiDsOJ7TOGHsPG07XXwIPeU3WRCNs3fEbe6gWQs4TM0rVUxqZRntyTSHpv4jv1J7XrADJ7DiB/21qKV/8P6bs/YUDVGhIsQrXHApBgEfLoyBedLiLl7KsZNPqbxMUnULgnh80LX6bdprcYXLGMdlbDPtpTFJNJRWwqVfHp1MSnE0nMwGPi6L37XXr4HgpJZ0OPK+k74Sd06/P3UXDB7h3s+PyvVH7xCRkFyzi9egMJVkuNx7I5YRBFXcaSeubF9DpzLGXFBZQW5LC/aCfVJXuoK91DTHke7fbnkVKdT0akkI5eQkwj/s+2xvSisAnCo55CpIGmDBGIfjLYvW0dlWUlwae9fdTu30dd5T5i4pPof8HVZHbp2WSvdySR2lp2bl1L/ublRCpLGXD+lXTo3K1R69bWVB/4lNsYFWUlVFfuP2QoNlZ1VSVbV39K0cZP8UgtMe1SiE1KJS4xlfikVBLap5LZ/fRG9+HL9ublsulvrxC/8W36VqxkY8Y4el/9r3TtNSB0zceiuqqSvB2bKNq5kZryYmorS6mrLIWqcry6lJjqcqzbMIZO/D7tU9IPux2vq2P5//yZtEX/h361X7A+YQgl/S6l79e+Q9feAw+7XsHObexcvwSAhNQOJKV0oH1aR5LTOpDUPhV3p7yshPKSQir27aWydC/VZUV4XQ3t0ruQnHEaKR1OI73jacf03oDorqV1f3uduMRkup2RRaeuvY5p/aZWUVbCpuz/oXz9+0AMHc69gjPO/joxsbGHXadsXxEb/vYaNZs+JL5qLwk1+0iq3UdypJRULyXZKlmTMIyKEdMY/o0bGrWLdn95KZuWvk/ZuvfomPcpA2o2HDbI69wosjSKYzMpS+hEVVIXIsldiUnrRrsO3QGorSrDqyqIVJXj1eVQU0FC9+GMnHBDk4RHPYVIA00dIiItxevq2F9ResTAkZYTqa097j/UpSV72bL0HfbnriEmpTOJGd1IzuxO+mk9ycjseszh3VyOFCLNeo91M/vfwA8AB1YCM4BuwPNAJrAUuMHdq82sHfAMcC5QCFzr7luD7dwN3AREgNvcfX7QPgl4FIgF/uTuDzRnf0Rak8XEKEBOIE3xST81vSMjLv5OE1TTeprtFF8z6wHcBmS5+1Cif+i/A/wWeMTdBwBFRMOB4GdR0P5IsBxmNiRY7yxgEvBHM4s1s1jgceBSYAhwXbCsiIi0kOb+nkgckGRmcUB7YBdwMfByMH8OcEUwPSV4TjD/EjOzoP15d69y9y+ATcDo4LHJ3be4ezXR0c2UZu6PiIg00Gwh4u65wO+A7UTDo4To7qtid6//tlsO0COY7gHsCNatDZbPbNj+pXUO1/4VZnazmWWbWXZ+vq7CKyLSVJpzd1YHoiODfkB3IJno7qgW5+5PunuWu2d17nzo0zpFROTYNefurG8AX7h7vrvXAK8CFwAZwe4tgJ5AbjCdC/QCCOanEz3AfqD9S+scrl1ERFpIc4bIdmCsmbUPjm1cAqwBPgCmBstMA14PpucFzwnmv+/R84/nAd8xs3Zm1g8YCCwGlgADzayfmSUQPfg+rxn7IyIiX9Jsp/i6+yIzexlYBtQCnwFPAm8Cz5vZfUHbU8EqTwHPmtkmYC/RUMDdV5vZi0QDqBa4xd0jAGb2U2A+0TO/nnb3xl8pUEREjpu+bCgiIkd0pC8b6lLwIiISmkJERERCU4iIiEhoChEREQlNISIiIqEpREREJDSFiIiIhKYQERGR0BQiIiISmkJERERCU4iIiEhoChEREQlNISIiIqEpREREJDSFiIiIhKYQERGR0BQiIiISmkJERERCU4iIiEhoChEREQlNISIiIqEpREREJDSFiIiIhKYQERGR0BQiIiISmkJERERCU4iIiEhoChEREQlNISIiIqEpREREJDSFiIiIhKYQERGR0BQiIiISmkJERERCU4iIiEhoChEREQlNISIiIqE1a4iYWYaZvWxm68xsrZmdZ2YdzexdM9sY/OwQLGtm9piZbTKzz83snAbbmRYsv9HMpjVoP9fMVgbrPGZm1pz9ERGRgzX3SORR4C/uPhgYAawF7gLec/eBwHvBc4BLgYHB42ZgJoCZdQR+DYwBRgO/rg+eYJkfNlhvUjP3R0REGmi2EDGzdOBC4CkAd69292JgCjAnWGwOcEUwPQV4xqM+BTLMrBswEXjX3fe6exHwLjApmJfm7p+6uwPPNNiWiIi0gOYcifQD8oFZZvaZmf3JzJKBLu6+K1hmN9AlmO4B7Giwfk7QdqT2nEO0f4WZ3Wxm2WaWnZ+ff5zdEhGRes0ZInHAOcBMdz8bKOfvu64ACEYQ3ow11L/Ok+6e5e5ZnTt3bu6XExFpM5ozRHKAHHdfFDx/mWio7Al2RRH8zAvm5wK9GqzfM2g7UnvPQ7SLiEgLabYQcffdwA4zGxQ0XQKsAeYB9WdYTQNeD6bnATcGZ2mNBUqC3V7zgQlm1iE4oD4BmB/M22dmY4Ozsm5ssC0REWkBcc28/VuB58wsAdgCzCAaXC+a2U3ANuCaYNm3gMuATUBFsCzuvtfM/hVYEix3r7vvDaZ/AswGkoC3g4eIiLQQix6WaDuysrI8Ozu7tcsQETlpmNlSd8861Dx9Y11EREJTiIiISGgKERERCU0hIiIioSlEREQkNIWIiIiEphAREZHQFCIiIhJac39jXUROcDU1NeTk5FBZWdnapUgrS0xMpGfPnsTHxzd6HYWISBuXk5NDamoqffv2RTcHbbvcncLCQnJycujXr1+j19PuLJE2rrKykszMTAVIG2dmZGZmHvOIVCEiIgoQAcK9DxQiIiISmkJERFpdSkpKa5cgISlEREQkNIWIiJww3J077riDoUOHMmzYMF544QUAdu3axYUXXsjIkSMZOnQoH330EZFIhOnTpx9Y9pFHHmnl6tsmneIrIgfc89+rWbNzX5Nuc0j3NH79D2c1atlXX32V5cuXs2LFCgoKChg1ahQXXnghf/7zn5k4cSK//OUviUQiVFRUsHz5cnJzc1m1ahUAxcXFTVq3NI5GIiJywli4cCHXXXcdsbGxdOnShfHjx7NkyRJGjRrFrFmz+M1vfsPKlStJTU2lf//+bNmyhVtvvZW//OUvpKWltXb5bZJGIiJyQGNHDC3twgsvZMGCBbz55ptMnz6df/zHf+TGG29kxYoVzJ8/nyeeeIIXX3yRp59+urVLbXM0EhGRE8a4ceN44YUXiEQi5Ofns2DBAkaPHs22bdvo0qULP/zhD/nBD37AsmXLKCgooK6ujquvvpr77ruPZcuWtXb5bZJGIiJywrjyyiv55JNPGDFiBGbGgw8+SNeuXZkzZw4PPfQQ8fHxpKSk8Mwzz5Cbm8uMGTOoq6sD4N///d9bufq2ydy9tWtoUVlZWZ6dnd3aZYicMNauXcuZZ57Z2mXICeJQ7wczW+ruWYdaXruzREQkNIWIiIiEphAREZHQGhUiZpZsZjHB9BlmdrmZNf6uJSIickpq7EhkAZBoZj2Ad4AbgNnNVZSIiJwcGhsi5u4VwFXAH93928CJ+a0kERFpMY0OETM7D7geeDNoi22ekkRE5GTR2BD5GXA3MNfdV5tZf+CD5itLRKRl/du//VuTbau4uJg//vGPB57v3LmTqVOnNtn2Afr27UtBQUGTbjOMRoWIu//V3S93998GB9gL3P22Zq5NRNogdz/wLfSWdLgQCVPPl0Oke/fuvPzyy8dV34mqUZc9MbM/Az8CIsASIM3MHnX3h5qzOBFpYW/fBbtXNu02uw6DSx844iJbt25l4sSJjBkzhqVLl3LNNdfwxhtvUFVVxZVXXsk999wDwDPPPMPvfvc7zIzhw4fz7LPPsnXrVr7//e9TUFBA586dmTVrFr1792b69OmkpaWRnZ3N7t27efDBB5k6dSq7du3i2muvZd++fdTW1jJz5kzefPNN9u/fz8iRIznrrLO4//77D6rnrbfe4qyzzqKsrAyAl19+mTfeeIPZs2ezZ88efvSjH7FlyxYAZs6cyWOPPcbmzZsZOXIk3/zmN7nllluYPHkyq1atorKykh//+MdkZ2cTFxfHww8/zEUXXcTs2bOZN28eFRUVbN68mSuvvJIHH3ywUf/EDz/88IGLT/7gBz/gZz/7GeXl5VxzzTXk5OQQiUT4l3/5F6699lruuusu5s2bR1xcHBMmTOB3v/td2P9ZoPHXzhri7vvM7HrgbeAuYCmgEBGRJrFx40bmzJnDvn37ePnll1m8eDHuzuWXX86CBQvIzMzkvvvu4+OPP6ZTp07s3bsXgFtvvZVp06Yxbdo0nn76aW677TZee+01IHozq4ULF7Ju3Touv/xypk6desh7k4wbN44//OEPLF++HIiGWn09Y8eOPWLdt912G+PHj2fu3LlEIhHKysp44IEHWLVq1UHbq/f4449jZqxcuZJ169YxYcIENmzYAMDy5cv57LPPaNeuHYMGDeLWW2+lV69eR3z9pUuXMmvWLBYtWoS7M2bMGMaPH8+WLVvo3r07b74ZPYxdUlJCYWEhc+fOZd26dZhZk9yDpbEhEh98L+QK4A/uXmNmbeuiWyJtwVFGDM2pT58+jB07ln/6p3/inXfe4eyzzwagrKyMjRs3smLFCr797W/TqVMnADp27AjAJ598wquvvgrADTfcwC9+8YsD27ziiiuIiYlhyJAh7NmzB4BRo0bx/e9/n5qaGq644gpGjhx5xHqO5v333+eZZ54BIDY2lvT0dIqKig67/MKFC7n11lsBGDx4MH369DkQIpdccgnp6ekADBkyhG3bth01RBYuXMiVV15JcnIyAFdddRUfffQRkyZN4uc//zl33nknkydPZty4cdTW1pKYmMhNN93E5MmTmTx58lH7dzSNPbD+f4GtQDKwwMz6AE17+zMRadPq/wi6O3fffTfLly9n+fLlbNq0iZtuuinUNtu1a3dguv5is/X3JunRowfTp08/EACHq6eemR2YrqysDFXP0TSsNzY2ltra2tDbOuOMM1i2bBnDhg3jV7/6Fffeey9xcXEsXryYqVOn8sYbbzBp0qTjrrmxB9Yfc/ce7n6ZR20DLjruVxcR+ZKJEyfy9NNPHzj+kJubS15eHhdffDEvvfQShYWFAAd2Z51//vk8//zzADz33HOMGzfuiNs/1L1JAOLj46mpqTnsel26dGHt2rXU1dUxd+7cA+2XXHIJM2fOBCASiVBSUkJqaiqlpaWH3M64ceN47rnnANiwYQPbt29n0KBBR/13OZxx48bx2muvUVFRQXl5OXPnzmXcuHHs3LmT9u3b873vfY877riDZcuWUVZWRklJCZdddhmPPPIIK1asCP269Rp7YD0d+DVwYdD0V+BeoOS4KxARaWDChAmsXbuW8847D4CUlBT+8z//k7POOotf/vKXjB8/ntjYWM4++2xmz57N73//e2bMmMFDDz104MD6kXz44YdfuTcJwM0338zw4cM555xzuP/++7+y3gMPPMDkyZPp3LkzWVlZB0Lu0Ucf5eabb+app54iNjaWmTNnct5553HBBRcwdOhQLr30Um655ZYD2/nJT37Cj3/8Y4YNG0ZcXByzZ88+aARyrM455xymT5/O6NGjgeiB9bPPPpv58+dzxx13EBMTQ3x8PDNnzqS0tJQpU6ZQWVmJu/Pwww+Hft16jbqfiJm9AqwC5gRNNwAj3P2qRqwbC2QDue4+2cz6Ac8DmUQPzt/g7tVm1g54BjgXKASudfetwTbuBm4ienbYbe4+P2ifBDxK9IuPf3L3o+7Q1f1ERA6m+4lIQ811P5HT3f3X7r4leNwD9G/kurcDaxs8/y3wiLsPAIqIhgPBz6Kg/ZFgOcxsCPAdopdZmQT80cxig3B6HLgUGAJcFywrIiItpLEhst/Mvlb/xMwuAPYfbSUz6wl8C/hT8NyAi4H6b93MIXrGF8AU/j7SeRm4JFh+CvC8u1e5+xfAJmB08NgUhFo10dHNlEb2R0TkpDBmzBhGjhx50GPlyib+Ls9xaOwpvj8CngmOjUB0BDGtEev9B/ALIDV4ngkUu3v9KQc5QI9gugewA8Dda82sJFi+B/Bpg202XGfHl9rHHKoIM7sZuBmgd+/ejShbROTEsGjRotYu4Ygae3bWCncfAQwHhrv72URHFIdlZpOBPHdfevxlHh93f9Lds9w9q3Pnzq1djojIKeOY7mzo7vvcvf77If94lMUvAC43s61EdzVdTPQgeIaZ1Y+AegK5wXQu0AsgmJ9O9AD7gfYvrXO4dhERaSHHc3tcO9JMd7/b3Xu6e1+iB8bfd/friV79t/5yltOA14Ppefx9F9nUYHkP2r9jZu2CM7sGAouJXsNroJn1M7OE4DXmHUd/RETkGDX2mMihhL3syZ3A82Z2H/AZ8FTQ/hTwrJltAvYSDQWCS8+/CKwBaoFb3D0CYGY/BeYTPcX3aXdfHbYzIiJy7I44EjGzUjPbd4hHKdC9sS/i7h+6++Rgeou7j3b3Ae7+bXevCtorg+cDgvlbGqx/v7uf7u6D3P3tBu1vufsZwbyvfjtIRE4KW7duZejQoQe1ffjhh0e8ttPs2bP56U9/2tylyVEccSTi7qlHmi8iIm3b8ezOEpFTzG8X/5Z1e9c16TYHdxzMnaPvbPTyW7Zs4eqrr+a73/1uo9c53D1FXnrpJe65554DV9ddsGABq1evZsaMGVRXV1NXV8crr7zCwIEDw3RNOL4D6yIiTWr9+vVcffXVzJ49m1GjRjV6vfp7inz++edcf/313HZb9Mar9957L/Pnz2fFihXMmxc97+aJJ57g9ttvZ/ny5WRnZ9OzZ89m6UtboZGIiBxwLCOGppafn8+UKVN49dVXGTJkCB9++GGj1z3cPUUuuOACpk+fzjXXXMNVV0Uv9Xfeeedx//33k5OTw1VXXaVRyHHSSERETgjp6en07t2bhQsXNtk2n3jiCe677z527NjBueeeS2FhId/97neZN28eSUlJXHbZZbz//vtN9nptkUYiInJCSEhIYO7cuUycOJGUlBS6d2/0CaAH7ilyww03HHRPkc2bNzNmzBjGjBnD22+/zY4dOygpKaF///7cdtttbN++nc8//5yLLz7iBTjkCDQSEZETRnJyMm+88QaPPPII+/Y1/uapv//975k1axbDhw/n2Wef5dFHHwXgjjvuYNiwYQwdOpTzzz+fESNG8OKLLzJ06FBGjhzJqlWruPHGG5urO21Co+4ncirR/UREDqb7iUhDzXU/ERERka/QMREROaHNmjXrwO6pehdccAGPP/54K1UkDSlERAR3J3oPuBPPjBkzmDFjRmuX0SaEObyh3VkibVxiYiKFhYWh/oDIqcPdKSwsJDEx8ZjW00hEpI3r2bMnOTk55Ofnt3Yp0soSExOP+Rv8ChGRNi4+Pp5+/fq1dhlyktLuLBERCU0hIiIioSlEREQkNIWIiIiEphAREZHQFCIiIhKaQkREREJTiIiISGgKERERCU0hIiIioSlEREQkNIWIiIiEphAREZHQFCIiIhKaQkREREJTiIiISGgKERERCU0hIiIioSlEREQkNIWIiIiEphAREZHQFCIiIhKaQl+HmmIAAAjUSURBVEREREJrthAxs15m9oGZrTGz1WZ2e9De0czeNbONwc8OQbuZ2WNmtsnMPjezcxpsa1qw/EYzm9ag/VwzWxms85iZWXP1R0REvqo5RyK1wM/dfQgwFrjFzIYAdwHvuftA4L3gOcClwMDgcTMwE6KhA/waGAOMBn5dHzzBMj9ssN6kZuyPiIh8SbOFiLvvcvdlwXQpsBboAUwB5gSLzQGuCKanAM941KdAhpl1AyYC77r7XncvAt4FJgXz0tz9U3d34JkG2xIRkRbQIsdEzKwvcDawCOji7ruCWbuBLsF0D2BHg9VygrYjteccov1Qr3+zmWWbWXZ+fv5x9UVERP6u2UPEzFKAV4Cfufu+hvOCEYQ3dw3u/qS7Z7l7VufOnZv75URE2oxmDREziycaIM+5+6tB855gVxTBz7ygPRfo1WD1nkHbkdp7HqJdRERaSHOenWXAU8Bad3+4wax5QP0ZVtOA1xu03xicpTUWKAl2e80HJphZh+CA+gRgfjBvn5mNDV7rxgbbEhGRFhDXjNu+ALgBWGlmy4O2fwYeAF40s5uAbcA1wby3gMuATUAFMAPA3fea2b8CS4Ll7nX3vcH0T4DZQBLwdvAQEZEWYtHDEm1HVlaWZ2dnt3YZIiInDTNb6u5Zh5qnb6yLiEhoChEREQlNISIiIqEpREREJDSFiIiIhKYQERGR0BQiIiISmkJERERCU4iIiEhoChEREQlNISIiIqEpREREJDSFiIiIhKYQERGR0BQiIiISmkJERERCU4iIiEhoChEREQlNISIiIqEpREREJDSFiIiIhKYQERGR0BQiIiISmkJERERCU4iIiEhoChEREQlNISIiIqEpREREJDSFiIiIhKYQERGR0BQiIiISmkJERERCU4iIiEhoChEREQlNISIiIqEpREREJDSFiIiIhHbSh4iZTTKz9Wa2yczuau16RETakpM6RMwsFngcuBQYAlxnZkNatyoRkbYjrrULOE6jgU3uvgXAzJ4HpgBrmvqFfrv4t6zbu66pNysi0iIGdxzMnaPvbPLtntQjEaAHsKPB85yg7SBmdrOZZZtZdn5+fosVJyJyqjvZRyKN4u5PAk8CZGVleZhtNEeCi4ic7E72kUgu0KvB855Bm4iItICTPUSWAAPNrJ+ZJQDfAea1ck0iIm3GSb07y91rzeynwHwgFnja3Ve3clkiIm3GSR0iAO7+FvBWa9chItIWney7s0REpBUpREREJDSFiIiIhKYQERGR0Mw91HfvTlpmlg9sC7l6J6CgCcs5WajfbYv63bY0pt993L3zoWa0uRA5HmaW7e5ZrV1HS1O/2xb1u2053n5rd5aIiISmEBERkdAUIsfmydYuoJWo322L+t22HFe/dUxERERC00hERERCU4iIiEhoCpFGMLNJZrbezDaZ2V2tXU9zMrOnzSzPzFY1aOtoZu+a2cbgZ4fWrLGpmVkvM/vAzNaY2Wozuz1oP6X7DWBmiWa22MxWBH2/J2jvZ2aLgvf8C8GtFk4pZhZrZp+Z2RvB81O+zwBmttXMVprZcjPLDtpCv9cVIkdhZrHA48ClwBDgOjMb0rpVNavZwKQvtd0FvOfuA4H3guenklrg5+4+BBgL3BL8H5/q/QaoAi529xHASGCSmY0Ffgs84u4DgCLgplassbncDqxt8Lwt9LneRe4+ssH3Q0K/1xUiRzca2OTuW9y9GngemNLKNTUbd18A7P1S8xRgTjA9B7iiRYtqZu6+y92XBdOlRP+w9OAU7zeAR5UFT+ODhwMXAy8H7adc382sJ/At4E/Bc+MU7/NRhH6vK0SOrgewo8HznKCtLeni7ruC6d1Al9YspjmZWV/gbGARbaTfwW6d5UAe8C6wGSh299pgkVPxPf8fwC+AuuB5Jqd+n+s58I6ZLTWzm4O20O/1k/6mVNKy3N3N7JQ8L9zMUoBXgJ+5+77oh9OoU7nf7h4BRppZBjAXGNzKJTUrM5sM5Ln7UjP7emvX0wq+5u65ZnYa8K6ZrWs481jf6xqJHF0u0KvB855BW1uyx8y6AQQ/81q5niZnZvFEA+Q5d381aD7l+92QuxcDHwDnARlmVv8h81R7z18AXG5mW4nunr4YeJRTu88HuHtu8DOP6IeG0RzHe10hcnRLgIHBmRsJwHeAea1cU0ubB0wLpqcBr7diLU0u2B/+FLDW3R9uMOuU7jeAmXUORiCYWRLwTaLHhD4ApgaLnVJ9d/e73b2nu/cl+vv8vrtfzync53pmlmxmqfXTwARgFcfxXtc31hvBzC4jug81Fnja3e9v5ZKajZn9F/B1opeH3gP8GngNeBHoTfQy+te4+5cPvp+0zOxrwEfASv6+j/yfiR4XOWX7DWBmw4keSI0l+qHyRXe/18z6E/2U3hH4DPieu1e1XqXNI9id9U/uPrkt9Dno49zgaRzwZ3e/38wyCfleV4iIiEho2p0lIiKhKURERCQ0hYiIiISmEBERkdAUIiIiEppCRKSJmVkkuEJq/aPJLtxoZn0bXmFZpLXpsiciTW+/u49s7SJEWoJGIiItJLiPw4PBvRwWm9mAoL2vmb1vZp+b2Xtm1jto72Jmc4N7fawws/ODTcWa2f8L7v/xTvBNc5FWoRARaXpJX9qddW2DeSXuPgz4A9GrIAD8Hpjj7sOB54DHgvbHgL8G9/o4B1gdtA8EHnf3s4Bi4Opm7o/IYekb6yJNzMzK3D3lEO1bid4Aaktwwcfd7p5pZgVAN3evCdp3uXsnM8sHeja89EZwqfp3g5sHYWZ3AvHufl/z90zkqzQSEWlZfpjpY9Hwek4RdGxTWpFCRKRlXdvg5yfB9MdEryYLcD3Ri0FC9DalP4YDN45Kb6kiRRpLn2BEml5ScKfAen9x9/rTfDuY2edERxPXBW23ArPM7A4gH5gRtN8OPGlmNxEdcfwY2IXICUTHRERaSHBMJMvdC1q7FpGmot1ZIiISmkYiIiISmkYiIiISmkJERERCU4iIiEhoChEREQlNISIiIqH9fwITycJ04hJeAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hThhqUAjU06a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_latent_space(vae, n=30, figsize=15):\n",
        "    # display a n*n 2D manifold of digits\n",
        "    digit_size = 28\n",
        "    scale = 1.0\n",
        "    figure = np.zeros((digit_size * n, digit_size * n))\n",
        "    # linearly spaced coordinates corresponding to the 2D plot\n",
        "    # of digit classes in the latent space\n",
        "    grid_x = np.linspace(-scale, scale, n)\n",
        "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
        "\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            z_sample = np.array([[xi, yi]])\n",
        "            x_decoded = vae.decoder.predict(z_sample)\n",
        "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "            figure[\n",
        "                i * digit_size : (i + 1) * digit_size,\n",
        "                j * digit_size : (j + 1) * digit_size,\n",
        "            ] = digit\n",
        "\n",
        "    plt.figure(figsize=(figsize, figsize))\n",
        "    start_range = digit_size // 2\n",
        "    end_range = n * digit_size + start_range\n",
        "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
        "    sample_range_x = np.round(grid_x, 1)\n",
        "    sample_range_y = np.round(grid_y, 1)\n",
        "    plt.xticks(pixel_range, sample_range_x)\n",
        "    plt.yticks(pixel_range, sample_range_y)\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.imshow(figure, cmap=\"Greys_r\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_latent_space(vae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "407oSZhqU06b"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_label_clusters(vae, data, labels):\n",
        "    # display a 2D plot of the digit classes in the latent space\n",
        "    z_mean, _, _ = vae.encoder.predict(data)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
        "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
        "\n",
        "plot_label_clusters(vae, x_train, y_train)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}