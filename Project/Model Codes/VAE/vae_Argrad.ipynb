{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do_HESZgU06R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Bi-pDTjU06V"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3ElzNLTU06W",
        "outputId": "234d97bc-d94e-4bec-ff85-06f5ef5a051b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 14, 14, 32)   320         ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 7, 7, 64)     18496       ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 3136)         0           ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 16)           50192       ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 2)            34          ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 2)            34          ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " sampling_1 (Sampling)          (None, 2)            0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 69,076\n",
            "Trainable params: 69,076\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "latent_dim = 2\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = layers.Conv2D(32, 3, activation=\"tanh\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"tanh\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16, activation=\"tanh\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B__dOjkVU06Y",
        "outputId": "44e55f67-fcd6-4cef-d8c2-262f69d47a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3136)              9408      \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 14, 14, 64)       36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 28, 28, 32)       18464     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 28, 28, 1)        289       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65,089\n",
            "Trainable params: 65,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(7 * 7 * 64, activation=\"tanh\")(latent_inputs)\n",
        "x = layers.Reshape((7, 7, 64))(x)\n",
        "x = layers.Conv2DTranspose(64, 3, activation=\"tanh\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"tanh\", strides=2, padding=\"same\")(x)\n",
        "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glkzM5YPU06Z"
      },
      "outputs": [],
      "source": [
        "\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZSRMxXiU06a",
        "outputId": "91c0b0e6-b1d2-4703-e4d7-e6b4c94f2cda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 14ms/step - loss: 346.5526 - reconstruction_loss: 255.0334 - kl_loss: 6.8744\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 202.3918 - reconstruction_loss: 194.9710 - kl_loss: 4.9934\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 194.9388 - reconstruction_loss: 190.0492 - kl_loss: 4.1525\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 192.1094 - reconstruction_loss: 187.4834 - kl_loss: 3.9918\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 189.9683 - reconstruction_loss: 185.6061 - kl_loss: 3.9037\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 187.9686 - reconstruction_loss: 183.8438 - kl_loss: 3.8775\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 186.5225 - reconstruction_loss: 182.3327 - kl_loss: 3.8730\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 185.0710 - reconstruction_loss: 181.1653 - kl_loss: 3.8809\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 184.3066 - reconstruction_loss: 180.3035 - kl_loss: 3.8945\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 183.5896 - reconstruction_loss: 179.6787 - kl_loss: 3.9155\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 183.3895 - reconstruction_loss: 179.1654 - kl_loss: 3.9415\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 182.8946 - reconstruction_loss: 178.7466 - kl_loss: 3.9678\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 182.4214 - reconstruction_loss: 178.4026 - kl_loss: 3.9961\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 182.2542 - reconstruction_loss: 178.1104 - kl_loss: 4.0263\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 181.7807 - reconstruction_loss: 177.8571 - kl_loss: 4.0517\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 181.6643 - reconstruction_loss: 177.6809 - kl_loss: 4.0773\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 181.5281 - reconstruction_loss: 177.4339 - kl_loss: 4.0995\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 181.3690 - reconstruction_loss: 177.2887 - kl_loss: 4.1189\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 181.4492 - reconstruction_loss: 177.1325 - kl_loss: 4.1365\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 181.5364 - reconstruction_loss: 176.9506 - kl_loss: 4.1545\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 4s 16ms/step - loss: 181.0347 - reconstruction_loss: 176.8392 - kl_loss: 4.1675\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 181.0562 - reconstruction_loss: 176.7286 - kl_loss: 4.1833\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.9036 - reconstruction_loss: 176.6379 - kl_loss: 4.1923\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.9000 - reconstruction_loss: 176.5191 - kl_loss: 4.2058\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.9159 - reconstruction_loss: 176.4448 - kl_loss: 4.2170\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.8457 - reconstruction_loss: 176.3196 - kl_loss: 4.2288\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.6365 - reconstruction_loss: 176.2703 - kl_loss: 4.2378\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.3721 - reconstruction_loss: 176.2054 - kl_loss: 4.2489\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.1931 - reconstruction_loss: 176.1454 - kl_loss: 4.2568\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.5002 - reconstruction_loss: 176.0535 - kl_loss: 4.2675\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.5068 - reconstruction_loss: 175.9934 - kl_loss: 4.2747\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.6228 - reconstruction_loss: 175.9447 - kl_loss: 4.2798\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 179.8713 - reconstruction_loss: 175.9032 - kl_loss: 4.2870\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.0264 - reconstruction_loss: 175.8718 - kl_loss: 4.2956\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.4076 - reconstruction_loss: 175.8181 - kl_loss: 4.3031\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.1451 - reconstruction_loss: 175.7862 - kl_loss: 4.3107\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.0673 - reconstruction_loss: 175.7271 - kl_loss: 4.3156\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.1581 - reconstruction_loss: 175.6835 - kl_loss: 4.3224\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 180.1791 - reconstruction_loss: 175.6394 - kl_loss: 4.3257\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 179.7662 - reconstruction_loss: 175.6395 - kl_loss: 4.3303\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 179.7782 - reconstruction_loss: 175.5942 - kl_loss: 4.3335\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 179.8931 - reconstruction_loss: 175.5741 - kl_loss: 4.3384\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 179.8394 - reconstruction_loss: 175.5093 - kl_loss: 4.3395\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 179.8768 - reconstruction_loss: 175.4883 - kl_loss: 4.3412\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 179.7010 - reconstruction_loss: 175.4534 - kl_loss: 4.3439\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 179.7197 - reconstruction_loss: 175.4414 - kl_loss: 4.3442\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 179.6025 - reconstruction_loss: 175.4157 - kl_loss: 4.3474\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 179.6309 - reconstruction_loss: 175.4054 - kl_loss: 4.3513\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 179.7201 - reconstruction_loss: 175.3621 - kl_loss: 4.3557\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 179.4666 - reconstruction_loss: 175.3333 - kl_loss: 4.3604\n"
          ]
        }
      ],
      "source": [
        "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
        "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
        "\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adagrad())\n",
        "history = vae.fit(mnist_digits, epochs=50, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "plt.figure(figsize=(10, 8))\n",
        "hist_df.plot()\n",
        "# hist_df.plot(y='reconstruction_loss', label='decoder loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('Losses_Adagrad.png',dpi=300)\n",
        "files.download(\"Losses_Adagrad.png\") \n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "W9M7wXa0jbNS",
        "outputId": "ae6bbf9e-d1b9-44d1-95da-babb333f7dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_81996d9b-4798-47f7-a4ab-13144651a536\", \"Losses_Adagrad.png\", 68623)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hThhqUAjU06a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_latent_space(vae, n=30, figsize=15):\n",
        "    # display a n*n 2D manifold of digits\n",
        "    digit_size = 28\n",
        "    scale = 1.0\n",
        "    figure = np.zeros((digit_size * n, digit_size * n))\n",
        "    # linearly spaced coordinates corresponding to the 2D plot\n",
        "    # of digit classes in the latent space\n",
        "    grid_x = np.linspace(-scale, scale, n)\n",
        "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
        "\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            z_sample = np.array([[xi, yi]])\n",
        "            x_decoded = vae.decoder.predict(z_sample)\n",
        "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "            figure[\n",
        "                i * digit_size : (i + 1) * digit_size,\n",
        "                j * digit_size : (j + 1) * digit_size,\n",
        "            ] = digit\n",
        "\n",
        "    plt.figure(figsize=(figsize, figsize))\n",
        "    start_range = digit_size // 2\n",
        "    end_range = n * digit_size + start_range\n",
        "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
        "    sample_range_x = np.round(grid_x, 1)\n",
        "    sample_range_y = np.round(grid_y, 1)\n",
        "    plt.xticks(pixel_range, sample_range_x)\n",
        "    plt.yticks(pixel_range, sample_range_y)\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.imshow(figure, cmap=\"Greys_r\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_latent_space(vae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "407oSZhqU06b"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_label_clusters(vae, data, labels):\n",
        "    # display a 2D plot of the digit classes in the latent space\n",
        "    z_mean, _, _ = vae.encoder.predict(data)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
        "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
        "\n",
        "plot_label_clusters(vae, x_train, y_train)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}